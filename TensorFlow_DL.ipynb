{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_17:0' shape=() dtype=int32>\n",
      "Tensor(\"Const_17:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# TENSORFLOW PROGRAM BASICS:\n",
    "      # Demo code to explain the basic concepts of Constants, Variables and Placeholders. \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# This is a Variable\n",
    "zero = tf.compat.v1.Variable(0)\n",
    "print(zero)\n",
    "\n",
    "# This is a constant\n",
    "one = tf.constant(1)\n",
    "print(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "new_value = tf.add(zero,one)  # We can add Variable & a constant. There is no Restrictions on it. \n",
    "print(new_value)     # here the value of new_value is 1. Because 0 and 1 addition is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHATGPT ASSISTANCE FOR TENSORFLOW 1.x COMPATIBILITY MODE. VIDEO DEPENDS ON TENSORFLOW 2.x COMPATIBILITY MODE. \n",
    "\n",
    "# Disable eager execution to use TensorFlow 1.x style\n",
    "tf.compat.v1.disable_eager_execution()                              # Version change code (do not consider)\n",
    "\n",
    "# Only for VARIABLES - we need to write a code to INITIALIZE it.    \n",
    "init_op = tf.compat.v1.global_variables_initializer()               # Must\n",
    "\n",
    "# Initialize the session                                            \n",
    "sess = tf.compat.v1.Session()                                       # Must"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Video) Initialize Variables:                 \n",
    "sess.run(init_op)                                                   # Must"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note only you can MODIFY Variables but not Constants. Example below:\n",
    "\n",
    "update_variable = tf.compat.v1.assign(zero,new_value) \n",
    "print(update_variable)\n",
    "\n",
    "# Zero is a variable, you can modify it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_constant = tf.compat.v1.assign(one,new_value)  # one is a constant ere. \n",
    "print(update_constant)\n",
    "\n",
    "# You cannot UPDATE / MODIFY constants.It will sowin you an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    sess.run(update_variable)\n",
    "    print(sess.run(zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once session is opened, it will remains open until closing the session. Need not to run again and again. \n",
    "\n",
    "# String operations\n",
    "Hello = tf.constant(\"Hello\")\n",
    "World = tf.constant(\"World\")\n",
    "HelloWorld = tf.add(Hello,World)\n",
    "print(sess.run(HelloWorld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place-holders:\n",
    "a = tf.compat.v1.placeholder(tf.float32) \n",
    "b = a*2\n",
    "\n",
    "# Note that in place-holder, we just mentioned the data type as a parameter.  \n",
    "# Now 'a' as no value, but later on sometimes - if 'a' gets any value, 'b' would be the twice of 'a'.\n",
    "# Meaning that 'a' and 'b' having the 'float' datatype. \n",
    "\n",
    "# feeding a place-holder with a scalar\n",
    "result = sess.run(b,feed_dict={a:3})  # or we can write -> sess.run(b,{a:3}). This also works. \n",
    "print(result)\n",
    "\n",
    "     # here using session, we run 'b' by feeding 'a' with a value. Nothing is difficult here.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding a place-holder with vector of rank 1.\n",
    "result1 = sess.run(b,feed_dict={a:[3,4,5]})   # feeding 'a' wit 1-D array (rank 1)\n",
    "print(result1)\n",
    "\n",
    "# feeding a place-holder with multi-dimensioanl vector.\n",
    "dictionary = {a:[[[1,2,3],[4,5,6],[7,8,9],[10,11,12]],[[13,14,15],[16,17,18],[19,20,21],[22,23,24]]]}\n",
    "result2 = sess.run(b,feed_dict=dictionary)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'HelloWorld'\n"
     ]
    }
   ],
   "source": [
    "# Common syntax for creatin session:\n",
    "\n",
    "import tensorflow as tf\n",
    "     # Disable eager execution\n",
    "tf.compat.v1.disable_eager_execution()  # for Version control only\n",
    "\n",
    "Hello = tf.constant(\"Hello\")\n",
    "World = tf.constant(\"World\")\n",
    "result = Hello+World\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    result3 = sess.run(result)\n",
    "    print(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(a)\n",
    "\n",
    "# Output is NameError: name 'a' is not defined.\n",
    "# Because we closed that session. \n",
    "# Either we should be inside the 'with' funtion else we should not close the session to run the particular function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN. JUST FOR CLARIFICATION\n",
    "\n",
    "# Question: how to re-open the closed session in Tensorflow? \n",
    "\n",
    "#Answer from ChatGpt:\n",
    "   # In TensorFlow 1.x, once a session is closed, you cannot re-open it. \n",
    "   # However, you can create a new session to continue your computations. \n",
    "   # If you need to continue where you left off, you'll need to save and restore the model's state using checkpoints.\n",
    "\n",
    "   # Here's an example of how to create a new session and restore the model's state from a checkpoint:\n",
    "\n",
    "       # Step 1: Define your graph and save a checkpoint:\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()    # for version control only\n",
    "\n",
    "# Define your operations\n",
    "Hello = tf.constant('Hello, ')\n",
    "World = tf.constant('World!')\n",
    "result = Hello + World\n",
    "\n",
    "# Create a session and run the operations\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Initialize the variables\n",
    "    sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "    # Save the model's state\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    saver.save(sess, 'my_model_checkpoint')\n",
    "\n",
    "    # Run and print the result\n",
    "    result3 = sess.run(result)\n",
    "    print(result3)\n",
    "\n",
    "\n",
    "      # Step2: Restore the model's state in a new session:\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Define your operations (must be the same as before)\n",
    "Hello = tf.constant('Hello, ')\n",
    "World = tf.constant('World!')\n",
    "result = Hello + World\n",
    "\n",
    "# Create a new session and restore the model's state\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    # Restore the model's state\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    saver.restore(sess, 'my_model_checkpoint')\n",
    "\n",
    "    # Run and print the result\n",
    "    result3 = sess.run(result)\n",
    "    print(result3)\n",
    "\n",
    "# In this example:\n",
    "   # We first create a session, run the operations, and save the model's state using a Saver object.\n",
    "   # We then create a new session, restore the model's state from the checkpoint, and run the operations again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo to explain Tensorflow programing structure: \n",
    "\n",
    "import tensorflow as tf\n",
    "# Disable eager execution to build a static computational graph\n",
    "tf.compat.v1.disable_eager_execution()      # for version control only\n",
    "\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "graph.get_operations()\n",
    "\n",
    "# Here the output is []. Because not any operations was performed so far yet. \n",
    "# If we performed any operations, it will shows an output of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"c_5:0\", shape=(), dtype=int32)\n",
      "Tensor(\"d_5:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant(10, name=\"c\")\n",
    "print(c)\n",
    "\n",
    "d = tf.constant(20, name=\"d\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'c' type=Const>, <tf.Operation 'd' type=Const>, <tf.Operation 'c_1' type=Const>, <tf.Operation 'd_1' type=Const>, <tf.Operation 'c_2' type=Const>, <tf.Operation 'd_2' type=Const>, <tf.Operation 'c_3' type=Const>, <tf.Operation 'd_3' type=Const>, <tf.Operation 'c_4' type=Const>, <tf.Operation 'd_4' type=Const>, <tf.Operation 'c_5' type=Const>, <tf.Operation 'd_5' type=Const>]\n"
     ]
    }
   ],
   "source": [
    "operations = graph.get_operations()    # to know what are all the operations got done. \n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"e_1:0\", shape=(), dtype=int32)\n",
      "[<tf.Operation 'c' type=Const>, <tf.Operation 'd' type=Const>, <tf.Operation 'c_1' type=Const>, <tf.Operation 'd_1' type=Const>, <tf.Operation 'c_2' type=Const>, <tf.Operation 'd_2' type=Const>, <tf.Operation 'c_3' type=Const>, <tf.Operation 'd_3' type=Const>, <tf.Operation 'c_4' type=Const>, <tf.Operation 'd_4' type=Const>, <tf.Operation 'c_5' type=Const>, <tf.Operation 'd_5' type=Const>, <tf.Operation 'e' type=AddV2>, <tf.Operation 'e_1' type=AddV2>]\n"
     ]
    }
   ],
   "source": [
    "# We are already and actually in the phase of building a graph: \n",
    "\n",
    "e = tf.add(c,d,name=\"e\")\n",
    "print(e)\n",
    "\n",
    "operations = graph.get_operations()\n",
    "print(operations)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'c' type=Const>, <tf.Operation 'd' type=Const>, <tf.Operation 'c_1' type=Const>, <tf.Operation 'd_1' type=Const>, <tf.Operation 'c_2' type=Const>, <tf.Operation 'd_2' type=Const>, <tf.Operation 'c_3' type=Const>, <tf.Operation 'd_3' type=Const>, <tf.Operation 'c_4' type=Const>, <tf.Operation 'd_4' type=Const>, <tf.Operation 'c_5' type=Const>, <tf.Operation 'd_5' type=Const>, <tf.Operation 'e' type=AddV2>, <tf.Operation 'e_1' type=AddV2>, <tf.Operation 'f' type=Mul>, <tf.Operation 'f_1' type=Mul>]\n"
     ]
    }
   ],
   "source": [
    "f = tf.multiply(c,d,name=\"f\")\n",
    "operations = graph.get_operations()\n",
    "print(operations)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.multiply(e,f,name=\"g\")\n",
    "operations = graph.get_operations()\n",
    "print(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "# Here may be a question raised for you. Now do I initialize Variables? \n",
    "# Here we use only CONSTANTS, so no need to initialize variables. \n",
    "\n",
    "# Initialize the session                                            \n",
    "sess1 = tf.compat.v1.Session()                                       # Must\n",
    "\n",
    "print(sess1.run(g))   # to get the value exactly as output - you need to run the session. \n",
    "\n",
    "# Output is 6000. \n",
    "# 'g' is the MULTIPLICATION of e & f. (e is the addition(30) of c(10) & d(20) then f is the multiplication(200) of c(10) & d(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in graph.get_operations():\n",
    "    print(op.name)\n",
    "\n",
    "# Just to et te names of all te operations performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LESSON 7: USE CASE IMPLEMENTATION USING TENSORFLOW:\n",
    "\n",
    "# Read in the census.data_csv data with pandas\n",
    "import pandas as pd\n",
    "\n",
    "census = pd.read_csv(\"D:\\Learnings and all\\Dataset\\Tensorflow\\What is Tensorflow\\census_data_What is Tensorflow.csv\")\n",
    "\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census[\"income_bracket\"].unique()  # output is array([' <=50K', ' >50K'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(labels):\n",
    "    if labels == \"<=50k\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "census[\"income_bracket\"] = census[\"income_bracket\"].apply(label_fix)   # Important -> apply() function.\n",
    "census[\"income_bracket\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM TRAIN TEST SPLIT ON CENSUS DATA:\n",
    "\n",
    "   # What is x and y in training data?\n",
    "      # In ML - X and y are commonly used to represent the input features and the corresponding target labels, respectively.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = census.drop(\"income_bracket\", axis=1)   # Means taking all data except income_bracket\n",
    "y_labels = census[\"income_bracket\"] # taking only this column as target label.\n",
    "X_train,X_test,y_train,y_test = train_test_split(x_data,y_labels,test_size=0.3, random_state=42)\n",
    "\n",
    "# Tensorflow offers an API called ESTIMATOR\n",
    "    # model = tf.estimator.LinearClassifier(feature_columns = feat_cols)\n",
    "    # model.train(input_fn = input_func,steps=5000)\n",
    "# Prepare feature columns and input function. \n",
    "\n",
    "  # (Two preparations we need to make before train our model - feat_cols & input_func.\n",
    "  # feat_cols - Below we seperated columns by data-type like Categorical columns and numerical columns.\n",
    "  # For INPUT_FUNC - we manually DEFINE it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# create tf.feature_columns for the categorical values. Use vocabulary lists or  just use hash-buckets:\n",
    "\n",
    "gender =tf.feature_column.categorical_column_with_vocabulary_list('gender',['Male','Female'])    # 2 cateories.\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket('occupation',hash_bucket_size=1000)   # more tan 2 cateories\n",
    "marital_status = tf.feature_column.categorical_column_with_hash_bucket('marital_status',hash_bucket_size=1000) # more tan 2 cateories\n",
    "relationship = tf.feature_column.categorical_column_with_hash_bucket('relationship',hash_bucket_size=1000) # more tan 2 cateories\n",
    "education = tf.feature_column.categorical_column_with_hash_bucket('education',hash_bucket_size=1000)  # more tan 2 cateories\n",
    "workclass = tf.feature_column.categorical_column_with_hash_bucket('workclass',hash_bucket_size=1000)  # more tan 2 cateories\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket('native_country',hash_bucket_size=1000)  # more tan 2 cateories\n",
    "\n",
    "# create tf.feature_columns for the continuous values. Using numeric_column:\n",
    "\n",
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "# Put all these variables into a single list with a variable name 'feat_cols'.\n",
    "feat_cols = [gender,occupation,marital_status,relationship,education,workclass,native_country,age,education_num,\n",
    "            capital_gain,capital_loss,hours_per_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "\n",
    "#Estimators will not be available in TensorFlow 2.16 or after. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input function:\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "  # input_func = tf.estimator.inputs.pandas_input_fn(x = X_train,y = y_train,batch_size=100,num_epochs = None,shuffle=True)\n",
    "         # The above is the actual and simply short-way code but it showing the below error because of version control. \n",
    "         # AttributeError: module 'tensorflow_estimator.python.estimator.api._v2.estimator' has no attribute 'input'\n",
    "\n",
    "  #(I uninstalled 2.16.2 version and re-installed 2.15.0 were ESTIMATOR Parameter is available.\n",
    "  # Even after INPUT function not available in this ESTIMATOR. Therefore I have manually DEFINE the input function. \n",
    "  # Luckily, LINEAR_CLASSIFIER function available in 2.15.0 versions ESTIMATOR.)\n",
    "\n",
    "# DEFINING INPUT function. \n",
    "\n",
    "X_train = x_data\n",
    "y_train = y_labels \n",
    "\n",
    "def input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
    "  def input_function():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(buffer_size=len(features))\n",
    "      dataset = dataset.batch(batch_size)\n",
    "      dataset = dataset.repeat(num_epochs)\n",
    "      return dataset\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = input_fn(X_train, y_train, batch_size=100, num_epochs=None)\n",
    "\n",
    "# Understand the format.\n",
    "# 'Batch size' is nothing but we cannot put the entire data in one shot when feeding the model. \n",
    "# We need to input batchwise data. Example: If there are 1000 rows, when we want to input 100,100,.. data as 10 times.\n",
    "# Here batch size is 100.\n",
    "# 'epocs' is nothing but how many times we pass the data (same data only) to train the model very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your model with tf.estimator:\n",
    "     # create a LinearClassifier:\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feat_cols)\n",
    "\n",
    "     # Train your model on the data, for atleast 5000 steps:\n",
    "model.train(input_fn=train_input_fn,steps=5000)\n",
    "\n",
    "  # (STEPS indicates that how many iterations this model needs to run). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATION:\n",
    "  # Create a prediction input function. Provide suffle=False.\n",
    "\n",
    "# pred_fn = train_input_fn(x = X_test, batch_size=len(X_test),shuffle = False)\n",
    "\n",
    "   #TypeError: 'NoneType' object is not callable error -occurs bcz you're trying to call train_input_fn directly with arguments. \n",
    "   # Instead, you need to create a separate input function for predictions.\n",
    "   # - similar to how you created train_input_fn, but with shuffle=False and adjusted parameters for prediction.\n",
    "   # Hereâ€™s how to define a prediction input function:\n",
    "\n",
    "   # Define Prediction Input Function\n",
    "\n",
    "def predict_input_fn(features, batch_size):\n",
    "    def input_function():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset\n",
    "    return input_function\n",
    "\n",
    "# Create prediction input function\n",
    "pred_fn = predict_input_fn(X_test, batch_size=len(X_test))\n",
    "\n",
    "\n",
    "  # Use model.predict() and pass in your input functions. This will produce a generator of prediction,\n",
    "  # - which you can then transform into a list, with list().\n",
    "predictions = list(model.predict(input_fn = pred_fn))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([0.], dtype=float32),\n",
       " 'logistic': array([0.5], dtype=float32),\n",
       " 'probabilities': array([0.5, 0.5], dtype=float32),\n",
       " 'class_ids': array([0], dtype=int64),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'all_class_ids': array([0, 1]),\n",
       " 'all_classes': array([b'0', b'1'], dtype=object)}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each item in your list will look like this.\n",
    "predictions[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create a list of only the 'class_ids' key values from the prediction list of dictionaries.\n",
    " # These are the predictions you will use to compare against the real y_test values. \n",
    "\n",
    "# Extract the class IDs from the predictions\n",
    "final_preds = [pred['class_ids'][0] for pred in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Classification report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data.\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERALL SAMPLE CODES FOR REFERENCE: \n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Sample training data\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4],\n",
    "    'feature2': [10, 20, 30, 40],\n",
    "}\n",
    "X_train = pd.DataFrame(data)\n",
    "y_train = pd.Series([' <=50K', ' >50K', ' <=50K', ' >50K'])\n",
    "\n",
    "# Sample test data\n",
    "X_test = pd.DataFrame({\n",
    "    'feature1': [5, 6],\n",
    "    'feature2': [50, 60]\n",
    "})\n",
    "y_test = pd.Series([' >50K', ' <=50K'])  # Add true labels for the test data\n",
    "\n",
    "# Map the string labels to integers\n",
    "label_mapping = {' <=50K': 0, ' >50K': 1}\n",
    "y_train_mapped = y_train.map(label_mapping)\n",
    "y_test_mapped = y_test.map(label_mapping)\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [tf.feature_column.numeric_column(key=key) for key in X_train.columns]\n",
    "\n",
    "# Define input function for training\n",
    "def input_fn(features, labels, batch_size, num_epochs=None, shuffle=True):\n",
    "    def input_function():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=len(features))  # buffer_size is set to dataset size\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        return dataset\n",
    "    return input_function\n",
    "\n",
    "# Create training input function\n",
    "batch_size = 100\n",
    "num_epochs = None  # or specify the number of epochs\n",
    "train_input_fn = input_fn(X_train, y_train_mapped, batch_size, num_epochs)\n",
    "\n",
    "# Create a LinearClassifier\n",
    "model = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "\n",
    "# Train your model on the data, for at least 5000 steps\n",
    "model.train(input_fn=train_input_fn, steps=5000)\n",
    "\n",
    "# Define input function for predictions\n",
    "def predict_input_fn(features, batch_size):\n",
    "    def input_function():\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset\n",
    "    return input_function\n",
    "\n",
    "# Create prediction input function\n",
    "pred_fn = predict_input_fn(X_test, batch_size=len(X_test))\n",
    "\n",
    "# Use model.predict() and pass in your input function\n",
    "predictions = list(model.predict(input_fn=pred_fn))\n",
    "\n",
    "# Extract the class IDs from the predictions\n",
    "final_preds = [pred['class_ids'][0] for pred in predictions]\n",
    "\n",
    "# Map the predicted integer labels back to the original string labels\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "final_preds_mapped = [reverse_label_mapping[pred] for pred in final_preds]\n",
    "\n",
    "# Evaluate the predictions\n",
    "print(classification_report(y_test, final_preds_mapped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESSON 8: TENSORFLOW OBJECT DETECTION: \n",
    "\n",
    "  # IMPORTS:\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import six.moves.urllib as urllib # type: ignore\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV SETUP\n",
    "  # Tis is needed to display te imaes:\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object detection imports\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from object_detection.utils import label_map_util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any model exported using the export_inference_graph.py tool can be loaded ere simply by  canin PAT_TO_CKPT to point to a new.pb file.\n",
    "# By default, we use an SSD WIT MOBILENET model ere. See te DETECTION MODEL ZOO for a list of oter models tat can be run out-of-te-box wit varyin speeds and accuracies. \n",
    "\n",
    "# Wat model to download:  (already trained model)\n",
    "MODEL_NAME = \"ssd_mobilenet_v1_coco_2017-11-17\"\n",
    "MODEL_FILE = MODEL_NAME + \".tar.gz\"\n",
    "DOWNLOAD_BASE = \"http://download.tensorflow.org/models/object_detection/\"\n",
    "\n",
    "# Pat to frozen detection rap. Tis is te actual model tat is used for te object-detection:\n",
    "PATH_TO_CKPT = MODEL_NAME + \"/frozen_inference_graph.pb\"\n",
    "\n",
    "# List of te strins tat is used to add correct label for eac box.\n",
    "PATH_TO_LABELS = os.path.join(\"data\",\"mscoco_label_map.pbtxt\")\n",
    "\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESSON 9: DEEP LEARNIN FRAMEWORKS: \n",
    "   # TensorFlow  | Keras | PyTorch | Theano | DL4J (Deep learning for Java) | Caffe | Chainer | Microsoft CNTK (Cognitive Toolkit)\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tensorflow.examples.tutorials.mnist import input_data  - Sowin error due to version control.\n",
    "\n",
    "# Importing MNIST data using the new method\n",
    "from tensorflow.keras.datasets import mnist # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESSON 12: WORKIN OF LSTMs.\n",
    "\n",
    "   # Use case implementation of LSTM\n",
    "\n",
    "#1.  Import Libraries:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2. Import te trainin dataset:\n",
    "dataset_train = pd.read_csv(\"D:\\Learnings and all\\Dataset\\RNN\\Google_Stock_Price_Train.csv\")\n",
    "training_set = dataset_train.iloc[:,1:2].values    #  It uses .values to convert the column into a NumPy array.\n",
    "\n",
    "# 3. Feature Scaling:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "    # Uses MinMaxScaler from scikit-learn to scale the training_set values between 0 and 1. \n",
    "    # This is a common preprocessing step for neural networks, especially when using activation functions like sigmoid or tanh.\n",
    "\n",
    "# 4. Creating a data structure with 60 timesteps and 1 output.\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(60,1258):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "X_train,y_train = np.array(X_train),np.array(y_train)\n",
    "\n",
    "   # Re-shaping:\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Importing te term libraries and packaes:\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Initialize te RNN:\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Adding te LSTM layers and some Dropout Reularization:\n",
    "\n",
    "   # Adding te first LSTM layer and some Dropout reularization:\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    " \n",
    "   # Adding te second LSTM layer and some Dropout reularization:\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "   # Adding te tird LSTM layer and some Dropout reularization:\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "   # Adding te fourt LSTM layer and some Dropout reularization:\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "   29:22/ _8:29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
